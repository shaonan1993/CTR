dataset: glue
subset: sst2
templates:
  11d1c505-9232-4c35-82a4-4c3642843e2e: !Template
    answer_choices: negative ||| positive
    id: 11d1c505-9232-4c35-82a4-4c3642843e2e
    jinja: '{{sentence}}
      {{"positive"}} or {{"negative"}}?  ||| {{
      answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: positive negative after
    reference: ''
  228fcae7-7f4c-4e3c-9ac4-e49b26bc103d: !Template
    answer_choices: negative ||| positive
    id: 228fcae7-7f4c-4e3c-9ac4-e49b26bc103d
    jinja: '"{{sentence}}".  {{"positive"}} or {{"negative"}}? ||| {{ answer_choices[label]
      }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: review
    reference: ''
  5aa0cea9-0f8d-454d-b25b-b0d4cda273b8: !Template
    answer_choices: sad ||| happy
    id: 5aa0cea9-0f8d-454d-b25b-b0d4cda273b8
    jinja: ' "{{sentence}}".  {{"sad"}} or {{"happy"}}? ||| {{ answer_choices[label]
      }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: said
    reference: ''
  63c6b2be-8ecd-42ad-88c7-0d1dc1a8323a: !Template
    answer_choices: negative ||| positive
    id: 63c6b2be-8ecd-42ad-88c7-0d1dc1a8323a
    jinja: ' {{"positive"}} or {{"negative"}}?

      {{sentence}}

      |||

      {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: following positive negative
    reference: ''
  6dd74cd5-e074-4612-9e96-c17ca88c3bc4: !Template
    answer_choices: bad ||| good
    id: 6dd74cd5-e074-4612-9e96-c17ca88c3bc4
    jinja: "{{sentence}}".{{"good"}} or {{"bad"}}? ||| {{ answer_choices[label] }}
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: happy or mad
    reference: ''
