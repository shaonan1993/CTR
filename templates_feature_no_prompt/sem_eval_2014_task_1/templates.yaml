dataset: sem_eval_2014_task_1
templates:
  14b0f0c7-0026-466f-8d9e-9dc6c32bf111: !Template
    answer_choices: No clear answer ||| yes ||| no
    id: 14b0f0c7-0026-466f-8d9e-9dc6c32bf111
    jinja: '"{{premise}}" "{{hypothesis}}"
      ? ||| {{answer_choices[entailment_judgment]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: premise_agree_hypothesis
    reference: ''
  2aa091cb-02ff-4c8c-964c-4c5e53df8c1b: !Template
    answer_choices: null
    id: 2aa091cb-02ff-4c8c-964c-4c5e53df8c1b
    jinja: ' "{{hypothesis}}" and "{{premise}}"

      ||| {{(((10*relatedness_score)|round)/10)}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Pearson correlation
      - Spearman correlation
      - Mean Squared Error
      original_task: true
    name: related_rate
    reference: ''
  75203dd2-5ec3-4e91-b95f-228ad9bd2010: !Template
    answer_choices: neither ||| entailing ||| contradicting
    id: 75203dd2-5ec3-4e91-b95f-228ad9bd2010
    jinja: "Sentence 1: \"{{hypothesis}}\" \nSentence 2: \"{{premise}}\"\nAre the\
      \ two sentences {{answer_choices[1]}} or {{answer_choices[2]}} each other? If \"{{answer_choices[0]}}\".\n||| {{answer_choices[entailment_judgment]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: entailing_or_contradicting
    reference: ''
  892c58fd-64f5-4059-8fb8-c74bc025ff40: !Template
    answer_choices: Neutral ||| Entailment ||| Contradiction
    id: 892c58fd-64f5-4059-8fb8-c74bc025ff40
    jinja: "Given the following hypothesis: {{hypothesis}}.\
      \ {{premise}}, {{answer_choices[0]}}, {{answer_choices[1]}}, {{answer_choices[2]}}\
      \ |||\n {{answer_choices[entailment_judgment]}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: entailment_relation
    reference: ''
  91a6b1db-be59-41bd-9eea-73bb7a4e7350: !Template
    answer_choices: Neutral ||| Entailment ||| Contradiction
    id: 91a6b1db-be59-41bd-9eea-73bb7a4e7350
    jinja: 'Given the hypothesis: {{hypothesis}} and the premise: {{premise}}.  {{answer_choices[0]}}, {{answer_choices[1]}} and {{answer_choices[2]}}||| {{answer_choices[entailment_judgment]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: entailment_label
    reference: ''
  a58fe8b4-f185-46a9-8fca-6dc66d0812be: !Template
    answer_choices: null
    id: a58fe8b4-f185-46a9-8fca-6dc66d0812be
    jinja: "Given the following hypothesis: {{hypothesis}}.\nAs well as the premise:\
      \ {{premise}},\
      \ |||   {{(((10*relatedness_score)|round)/10)}}\n\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Pearson correlation
      - Spearman correlation
      - Mean Squared Error
      original_task: true
    name: related_score
    reference: ''
  d9380ec0-18b3-48b2-99eb-9f9cb47ab7c7: !Template
    answer_choices: unclear ||| yes ||| no
    id: d9380ec0-18b3-48b2-99eb-9f9cb47ab7c7
    jinja: Does {{premise}} imply that {{hypothesis}}?  ||| {{answer_choices[entailment_judgment]}}
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: premise_imply_hypothesis
    reference: ''
